---
title: "Magister en Estadística Aplicada"
author: "Curso:Modelos Lineales (Cohorte 2019-2020)"
date: "Guia de Actividades 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = NA, background = NA, results='asis')
```

```{r echo=FALSE}
## CONFIGURACIONES INICIALES
library("mat2tex")
ECHO_A<-TRUE
```

## Ejercicio 1
```{r echo=FALSE}
U1=matrix(c(0,0,0),nrow=3,byrow=TRUE)
W1=matrix(c(3,1,0,1,2,1,0,1,4),nrow=3,byrow=TRUE)
```

Sea $X \sim N_3(0,\sum)$ con: X=
```{r echo=FALSE,results='asis'}
"$" %_% xm(U1, mtype = "bm")  %_% "$"
```
y $\sum =$ 
```{r echo=FALSE,results='asis'}
"$" %_% xm(W1, mtype = "bm") %_% "$"
```

a. Encontrar las distribuciones marginales de $X_1$ y $X_3$.
```{r echo=ECHO_A,results='asis'}
## Primer elemento del vector de medias para obtener media de X1
U1_1=U1[1]
## Primer elemento diagonal de la matriz de varianza-covarianza para obtener la varianza de X1
W1_1=W1[1,1]
## Primer elemento del vector de medias para obtener media de X3
U1_3=U1[3]
## Primer elemento diagonal de la matriz de varianza-covarianza para obtener la varianza de X3
W1_3=W1[3,3]
```

$X_1 \sim N($
```{r echo=FALSE,results='asis'}
"$" %_% xm(U1_1, mtype = "bm") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(W1_1, mtype = "bm") %_% "$"
```
) y $X_3 \sim N($
```{r echo=FALSE,results='asis'}
"$" %_% xm(U1_3, mtype = "bm") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(W1_3, mtype = "bm") %_% "$"
```

b. Encontrar la distribución conjunta de $X_1$ y $X_2$.
```{r echo=ECHO_A,results='asis'}
## Primer y Segundo elemento del vector de medias
U1_12=U1[1:2]
## Submatriz de la matriz de varianza-covarianza
W1_12=W1[1:2,1:2]
```

$X_{12} \sim N_2($
```{r echo=FALSE,results='asis'}
"$" %_% xm(U1_12, mtype = "bm") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(W1_12, mtype = "bm") %_% "$"
```

c. Encontrar la distribución condicional de $X_2 \mid X_1=x_1, X_3=x_3$.
```{r echo=ECHO_A,results='asis'}
# ESPERANZAS
U=matrix(c(0,0,0),nrow=3,byrow=TRUE)
U_1=matrix(c(0),nrow=1,byrow=TRUE)
U_2=matrix(c(0,0),nrow=2,byrow=TRUE)
# VARIANZAS-COVARIANZAS
W=matrix(c(3,1,0,1,2,1,0,1,4),nrow=3,byrow=TRUE)
W11=matrix(c(2),nrow=1,byrow=TRUE)
W21=matrix(c(1,1),nrow=2,byrow=TRUE)
W12=matrix(c(1,1),nrow=1,byrow=TRUE)
W22=matrix(c(3,0,0,4),nrow=2,byrow=TRUE)
W22_inv=solve(W22)
# ESPERANZA CONDICIONAL
U1_2=U_1+W12%*%W22_inv%*%U_2
# COVARIANZA CONDICIONAL
W11_2=W11-W12%*%W22_inv%*%W21
```
$X_2 \mid X_1=x_1, X_3=x_3 \sim N($ 
```{r echo=FALSE,results='asis'}
"$" %_% xm(U1_2, mtype = "bm") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(W11_2, mtype = "bm") %_% "$"
```
$)$

d. Encontrar la matriz de correlación.
```{r echo=ECHO_A,results='asis'}
### obtiene matriz diagonal
W_diag=diag(diag(W))
#calcula raiz de inversa 
W_diag_inv=sqrt(solve(W_diag))
# obtiene correlacion
R=W_diag_inv%*%W%*%W_diag_inv
```
$R=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(R, mtype = "bm") %_% "$"
```

e. Encontrar $\rho_{{13}\mid 2} ,\rho_{{12}\mid 3}$.
```{r echo=ECHO_A,results='asis'}
## CORRELACION  DE 13 DADO 2
W11=matrix(c(3,0,0,4),nrow=2,byrow=TRUE)
W21=matrix(c(1,1),nrow=1,byrow=TRUE)
W12=matrix(c(1,1),nrow=2,byrow=TRUE)
W22=matrix(c(2),nrow=1,byrow=TRUE)

W22_inv=solve(W22)
# VARIANZA CONDICIONAL
W11_2=W11-(W12%*%W22_inv%*%W21)
# CORRELACION CONDICIONAL
W_diag=diag(diag(W11_2))
#calcula raiz de inversa 
W_diag_inv=sqrt(solve(W_diag))
# obtiene correlacion
R=W_diag_inv%*%W11_2%*%W_diag_inv
```

$\rho_{{13}\mid 2}=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(R, mtype = "bm") %_% "$"
```

```{r echo=ECHO_A,results='asis'}
## CORRELACION  DE 12 DADO 3
W11=matrix(c(3,1,1,2),nrow=2,byrow=TRUE)
W21=matrix(c(0,1),nrow=1,byrow=TRUE)
W12=matrix(c(0,1),nrow=2,byrow=TRUE)
W22=matrix(c(4),nrow=1,byrow=TRUE)
W22_inv=solve(W22)
# VARIANZA CONDICIONAL
W11_2=W11-(W12%*%W22_inv%*%W21)
W_diag=diag(diag(W11_2))
#calcula raiz de inversa 
W_diag_inv=sqrt(solve(W_diag))
# obtiene correlacion
R=W_diag_inv%*%W11_2%*%W_diag_inv
```

$\rho_{{12}\mid 3}=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(R, mtype = "bm") %_% "$"
```

f. Encontrar la distribución de $Z=3x_1 - 2x_2 -11$.
```{r echo=ECHO_A,results='asis'}
# Vector de Esperanzas de X1 y X2
U=matrix(c(0,0),nrow=2,byrow=TRUE)
# Varianza-Covarianza de X1 y X2
W=matrix(c(3,1,1,2),nrow=2,byrow=TRUE)
# Constantes de Multiplicación
A=matrix(c(3,-2),nrow=2,byrow=TRUE)
# Constante de Adición
B<--11
# Esperanza de Z
U_Z=t(A)%*%U+B
## Varianza de Z
VAR_Z=t(A)%*%W%*%A
```
$Z \sim N($ 
```{r echo=FALSE,results='asis'}
"$" %_% xm(U_Z, mtype = "m") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(VAR_Z, mtype = "m") %_% "$"
```
$)$

g. Encontrar la covarianza entre $Z_1$ y $Z_2$ donde $Z_1=2 X_1 -3 X_2+X_3 -3$ Y $Z_2=3 X_3+2$.

```{r echo=ECHO_A,results='asis'}
W=matrix(c(3,1,0,1,2,1,0,1,4),nrow=3,byrow=TRUE)
A=matrix(c(2,-3,1),nrow=3,byrow=TRUE)
B=matrix(c(0,0,3),nrow=3,byrow=TRUE)
VAR_Z1=t(A)%*%W%*%A
VAR_Z2=t(B)%*%W%*%B
COV_Z1_Z2=t(A)%*%W%*%B

```
$Cov(Z_1,Z_2)=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(COV_Z1_Z2, mtype = "m") %_% "$"
```

## Ejercicio 2

```{r echo=FALSE,results='asis'}
library(readxl)
calefaccion <- read_excel("calefaccion.xlsx")
```

En el archivo *calefacción* se muestran datos correspondientes a una población de 20 inmuebles ubicados en cierta zona residencial. Se consideran tres variables que están relacionadas con el costo de calefacción de la vivienda: la temperatura exterior media diaria ($X_1$), el número de cm. de aislamiento térmico de las paredes ($X_2$) y la antiguedad del calefactor ($X_3$).
a. Obtener el vector de medias y la matriz de varianzas y covarianzas del vector $X´= (X_1 X_2 X_3)$.
```{r echo=ECHO_A,results='asis'}
n=dim(calefaccion)[1]
unos=matrix(rep(1,n),nrow=n,byrow=TRUE)
X=as.matrix(calefaccion)
n=dim(calefaccion)[1]
#Vector de Medias
media=(1/n)*(t(X)%*%unos)
m_medias<-c(rep(media[1],n),rep(media[2],n),rep(media[3],n))
m_medias<-matrix(m_medias,ncol=3,byrow=FALSE)
X_c=X-m_medias
#Matriz de Varianzas y Covarianzas
Var =(1/n) *(t(X_c)%*%X_c)
```

$X \sim N($
```{r echo=FALSE,results='asis'}
"$" %_% xm(media, mtype = "bm") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(Var, mtype = "bm") %_% "$"
```
$)$

b. Obtener la matriz de correlación.

```{r echo=ECHO_A,results='asis'}
m_desv<-(c(rep(Var[1,1],n),rep(Var[2,2],n),rep(Var[3,3],n)))^0.5
m_desv<-matrix(m_desv,ncol=3,byrow=FALSE)
X_std<-X_c/m_desv
# Matriz de Correlación
Corr= (1/n)* t(X_std)%*%X_std
```

$\rho_X=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(Corr, mtype = "bm") %_% "$"
```

c. Obtener la matriz de correlación parcial de $X^{(1)}= (X_1 X_2$ dado $X^{(2)}=X_3$.

```{r echo=ECHO_A,results='asis'}
W11<-Var[1:2,1:2]
W21<-matrix(Var[1:2,3],ncol =2,byrow=TRUE)
W12<-matrix(Var[1:2,3],ncol =1,byrow=TRUE)
W22<-Var[3,3]
W22_inv=solve(W22)
# MATRIZ DE VARIANZAS CONDICIONALES
W11_2=W11-W12%*%W22_inv%*%W21
### DIAGONALIZA MATRIZ
W_diag=diag(diag(W11_2))
#RAIZ DE LA INVERSA
W_diag_inv=sqrt(solve(W_diag))
# CORRELACION PARCIAL
R=W_diag_inv%*%W11_2%*%W_diag_inv
```
$\rho_{X_1,X_2 \mid X_3 }=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(R, mtype = "bm") %_% "$"
```

## Ejercicio 3

```{r echo=FALSE}
UU<-matrix(c(2,1,4),ncol =1,byrow=TRUE)
WW<-matrix(c(2,-1,0,-1,4,0,0,0,1),ncol =3,byrow=FALSE)
```

Sea $X \sim N_3(\mu,\sum)$ con: $\mu$=
```{r echo=FALSE,results='asis'}
"$" %_% xm(UU, mtype = "bm")  %_% "$"
```
y $\sum =$ 
```{r echo=FALSE,results='asis'}
"$" %_% xm(WW, mtype = "bm") %_% "$"
```

a. Encontrar la distribución conjunta de $X_1$ y $X_2$.
```{r echo=ECHO_A,results='asis'}
# Vector de Esperanzas
U_1<-UU[1:2]
U_2<-UU[3]
# Varianzas/Covarianzas
W11<-WW[1:2,1:2]
```

$X_{1,2} \sim N_2($
```{r echo=FALSE,results='asis'}
"$" %_% xm(U_1, mtype = "bm") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(W11, mtype = "bm") %_% "$"
```
$)$

b. Encontrar la distribución condicional de $X_1=x_1, X_2=x_2 \mid X_3=x_3$, la esperanza y varianza.
```{r echo=ECHO_A,results='asis'}
U<-matrix(c(2,1,4),ncol =1,byrow=TRUE)
W<-matrix(c(2,-1,0,-1,4,0,0,0,1),ncol =3,byrow=FALSE)
W21=matrix(W[1:2,3],nrow=1,byrow=TRUE)
W12=matrix(W[1:2,3],nrow=2,byrow=TRUE)
W22=matrix(W[3,3],nrow=1,byrow=TRUE)
W22_inv=solve(W22)
U_1<-U[1:2]
U_2<-U[3]
# Esperanza Condicional
U1_2=U_1+W12%*%W22_inv%*%U_2
# Varianza/Covarianza Condicional
W11_2=W11-W12%*%W22_inv%*%W21
```

$X_1=x_1, X_2=x_2 \mid X_3=x_3 \sim N_2($
```{r echo=FALSE,results='asis'}
"$" %_% xm(U1_2, mtype = "bm") %_% "$"
```
,
```{r echo=FALSE,results='asis'}
"$" %_% xm(W11_2, mtype = "bm") %_% "$"
```
$)$

## Ejercicio 4

```{r echo=FALSE}
U<-matrix(c(0,0,0),ncol =1,byrow=TRUE)
W<- matrix(c(7,2,1,2,7,-1,1,-1,4),3,3) 
```

Sea $X \sim N_3(0,I)$, encontrar la transformación $CX$ tal que la matriz de covarianzas de la variable resultante sea:$\sum =$ 
```{r echo=FALSE,results='asis'}
"$" %_% xm(W, mtype = "bm") %_% "$"
```
. (Ayuda. Pensar en descomposición espectral o descomposición de Cholesky)

```{r echo=ECHO_A,results='asis'}
### DESCOMPOSICIÓN DE CHOLESKY DE LA MATRIZ W
C <- chol(W) 
## COMPROBAMOS LA DESCOMPOSICION REALIZADA
## t(C)%*%C
WO<- t(C)%*%diag(3)%*%C
```
La matriz $C$ producto de la descomposición de Cholesky es:
$C=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(C, mtype = "bm") %_% "$"
```
tal que:$$C´IC=$$
```{r echo=FALSE,results='asis'}
"$" %_% xm(t(C), mtype = "bm") %_% "$"
```
$x$
```{r echo=FALSE,results='asis'}
"$" %_% xm(diag(3), mtype = "bm") %_% "$"
```
$x$
```{r echo=FALSE,results='asis'}
"$" %_% xm(C, mtype = "bm") %_% "$"
```
$=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(W, mtype = "bm") %_% "$"
```

## Ejercicio 5

```{r echo=FALSE}
UUUU<-matrix(c(1,2),ncol =1,byrow=TRUE)
WWWW<- matrix(c(3,1,1,3),2,2) 
```

Dada $X\sim N_2($
```{r echo=FALSE,results='asis'}
"$" %_% xm(UUUU, mtype = "bm")  %_% "$"
```
, 
```{r echo=FALSE,results='asis'}
"$" %_% xm(WWWW, mtype = "bm") %_% "$"
```
$)$ encontrar la transformación $Y=TX+c$ tal que $Y\sim N_3(0,I)$

```{r echo=ECHO_A,results='asis'}
### SEA X CON DISTRIBUCIÓN N3 Y ESPERANZA 1,2 Y VARIANZA-COVARIANZA:
W<- matrix(c(3,1,1,3),2,2) 
### DESCOMPOSICIÓN DE CHOLESKY DE LA MATRIZ W
C <- chol(W) 
## COMPROBAMOS LA DESCOMPOSICION REALIZADA
## t(C)%*%C
### inversa de la raiz de matriz de varianza-covarianza
C_inv<-solve(C)
### constante de desplazamiento
c<-c(-1,-2)
## Verificamos T
##t(C_inv)%*%W%*%C_inv
```

La matriz $T$ producto de la descomposición de Cholesky es:
$T=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(C_inv, mtype = "bm") %_% "$"
```
y $c=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(c, mtype = "bm") %_% "$"
```


## Ejercicio 6

En el ejercicio anterior la función de densidad multivariada está dada por:
$f(x)=(2\pi)^{-1} \mid\sum\mid^{-1/2} e^{-1/2[(x-\mu)´(x-\mu)]}$ donde $Q=(x-\mu)´\sum^{-1}(x-\mu)$ es una forma cuadrática que mide el cuadrado de la distancia entre cada punto del plano y el vector de medias $\mu$. Encontrar la distribución de dicha forma cuadrática.

```{r echo=ECHO_A,results='asis'}
W<- matrix(c(3,1,1,3),2,2) 
la.qr <- qr(W)
# se listan los atributos del objeto anterior
# names(la.qr)
# se extrae el atributo rango
# print(c("El rango de la matriz es",la.qr$rank),quote = F)

```
Si $Y´AY \sim N(\mu,\sum)$ si $A$ es simétrica de rango K y $A\sum$ idempotente, tenemos que $YAY \sim \chi^2_{(rango(A),1/2 \mu´A \mu)}$
Ya que $A=\sum^{-1}$, $A\sum=\sum^{-1}\sum=I$ e $I$ es idempotente y $\sum{-1}$ es simétrica $$Q=(x-\mu)´\sum^{-1}(x-\mu) \sim \chi^2_{(2,0)} $$

## Ejercicio 7
```{r echo=FALSE,results='asis'}
B<- matrix(c(2,-1,-1,0,0,1),2,3) 
A<- matrix(c(1/6,1/3,1/6,1/3,2/3,1/3,1/6,1/3,1/6),3,3) 
```

Dado $Y\sim N_3(\mu,I)$ establecer si el vector $BY$ es independiente de la forma cuadrática $Y´AY$ donde: $B=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(B, mtype = "bm") %_% "$"
```
y $A=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(A, mtype = "bm") %_% "$"
```

```{r echo=ECHO_A,results='asis'}
B<- matrix(c(2,-1,-1,0,0,1),2,3) 
A<- matrix(c(1/6,1/3,1/6,1/3,2/3,1/3,1/6,1/3,1/6),3,3) 
BA<-B%*%A
```
Como: 
```{r echo=FALSE,results='asis'}
"$" %_% xm(B, mtype = "bm") %_% "$"
```
```{r echo=FALSE,results='asis'}
"$" %_% xm(A, mtype = "bm") %_% "$"
```
$=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(BA, mtype = "bm") %_% "$"
```
, la independencia se cumple.

## Ejercicio 8

```{r echo=FALSE,results='asis'}
A<- matrix(c(2,-1,-1,1),2,2)
B<- matrix(c(0.5,-1,0.5,1),2,2)
W5<- matrix(c(1,1,1,2),2,2)
U5<-matrix(c(1,3),2,1)
```

Dado $Y\sim N_2($
```{r echo=FALSE,results='asis'}
"$" %_% xm(U5, mtype = "bm")  %_% "$"
```
, 
```{r echo=FALSE,results='asis'}
"$" %_% xm(W5, mtype = "bm") %_% "$"
```
$)$, con: $B=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(B, mtype = "bm") %_% "$"
```
y $A=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(A, mtype = "bm") %_% "$"
```

a. Probar si la forma linear $BY$ es independiente de la forma cuadrática $Y´AY$.

```{r echo=ECHO_A,results='asis'}
A<- matrix(c(2,-1,-1,1),2,2)
B<- matrix(c(0.5,-1,0.5,1),2,2)
W<- matrix(c(1,1,1,2),2,2)
U<-matrix(c(1,3),2,1)
### INCISO A: PROBAR LA INDEPENDENCIA DE BY y Y´AY
BA<-B%*%A
```

Como: 
```{r echo=FALSE,results='asis'}
"$" %_% xm(B, mtype = "bm") %_% "$"
```
```{r echo=FALSE,results='asis'}
"$" %_% xm(A, mtype = "bm") %_% "$"
```
$=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(BA, mtype = "bm") %_% "$"
```
, la independencia *NO* se cumple.

b. Determinar la distribución de la forma cuadrática $Y´AY$.

```{r echo=ECHO_A,results='asis'}
## A ES SIMETRICA
## VEMOS SI LA FORMA AW ES IDENPOTENTE
AW<-A%*%W
## AW%*%AW
### AW ES IDENPOTENTE
### ENTONCES RANGO DE W:
la.qr <- qr(W)
# names(la.qr)
# print(c("El rango de la matriz es",la.qr$rank),quote = F)
### EL PARAMETRO DE NO CENTRALIDAD: 1/2 U´w U
nocen<- 0.5*t(U)%*%W%*%U
```

Si $Y´AY \sim N(\mu,\sum)$ si $A$ es simétrica de rango K y $A\sum$ idempotente, tenemos que $YAY \sim \chi^2_{(rango(A),1/2 \mu´A \mu)}$. El rango K es: `r la.qr$rank` y el parámetro de no centralidad es:`r nocen`, por lo que $Y´AY \sim \chi^2_{(2,12.5)}$

## Ejercicio 9

```{r echo=FALSE,results='asis'}
A9<- matrix(c(3,0.5,0.5,2),2,2)
B9<- matrix(c(2,-1,-1,1),2,2)
W9<- matrix(c(1,1,1,2),2,2)
```
Con $Y$ y $\sum$ como en el ejercicio anterior, establezca si las formas cuadráticas $Y´BY$ e $Y´AY$ son independientes, donde: $B=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(B9, mtype = "bm") %_% "$"
```
y $A=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(A9, mtype = "bm") %_% "$"
```

```{r echo=ECHO_A,results='asis'}
A<- matrix(c(3,0.5,0.5,2),2,2)
B<- matrix(c(2,-1,-1,1),2,2)
W<- matrix(c(1,1,1,2),2,2)
### INCISO A: PROBAR LA INDEPENDENCIA DE Y´BY y Y´AY
BA<- B%*%W%*%A

# NO SON INDEPENDIENTES
```
Como $B\sum A=$
```{r echo=FALSE,results='asis'}
"$" %_% xm(BA, mtype = "bm") %_% "$"
```
, las formas cuadráticas no son independientes.

## Ejercicio 10

El estadístico $T$ para la prueba de hipótesis de diferencia de medias está dado por:
$$T=\frac{(\overline{X}_1-\overline{X}_2)-(\mu_1-\mu_2)}{\sqrt[2]{S_P^2(\frac{1}{n_1}+\frac{1}{n_2}) }}$$
a. Demuestre que este estadístico tiene distribución *t-Student* con $(n_1+n_2-2)$ grados de libertad cuando $(\overline{X}_1-\overline{X}_2)$ es obtenida a partír de muestras aleatorias simples e independientes de tamaños $n_1$ y $n_2$, de poblaciones normales con idéntica varianza ($\sigma^2$)y esperanzas $\mu_1$ y $\mu_2$.
$T=\frac{(\overline{X}_1-\overline{X}_2)-(\mu_1-\mu_2)}{\sqrt[2]{S_P^2(\frac{1}{n_1}+\frac{1}{n_2}) }}\frac{\sigma}{\sigma}$
$=\frac{(\overline{X}_1-\overline{X}_2)-(\mu_1-\mu_2)}{\sqrt[2]{\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}}\sqrt[2]{\frac{1}{n_1}+\frac{1}{n_2} }}\frac{\sigma}{\sigma}$

$=\frac{(\overline{X}_1-\overline{X}_2)-(\mu_1-\mu_2)}{\sigma\sqrt[]{\frac{1}{n_1}+\frac{1}{n_2}}}:\sqrt[]{[\frac{(n_1-1)S_1^2}{\sigma^2}+\frac{(n_2-1)S_2^2}{\sigma^2}]\frac{1}{n_1+n_2-2}}$
donde es posible apreciar que:
$$Z=\frac{(\overline{X}_1-\overline{X}_2)-(\mu_1-\mu_2)}{\sigma\sqrt[]{\frac{1}{n_1}+\frac{1}{n_2}}} \sim N(0,1) $$
$$U=[\frac{(n_1-1)S_1^2}{\sigma^2}+\frac{(n_2-1)S_2^2}{\sigma^2}]\sim \chi^2_{(n+m-2)}$$
$$T=\frac{Z}{\sqrt[]{\frac{U}{n+m-2}}}\sim \tau(n+m-2) $$
b.  Demostrar que: $S^2_p={\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}}$ es un estimador insesgado de $\sigma^2$.
$E(S^2_p)=E({\frac{(n_1-1)S_1^2+(n_2-1)S_2^2}{n_1+n_2-2}})$
$={\frac{(n_1-1)E(S_1^2)+(n_2-1)E(S_2^2)}{n_1+n_2-2}}$
$={\frac{(n_1-1)\sigma^2+(n_2-1)\sigma^2}{n_1+n_2-2}}$
$=\frac{(n-1)+(m-1)}{n+m-2}\sigma^2$
$$E(S^2_p)=\sigma^2$$

## Ejercicio 11

El estadístico $F$ para la prueba de hipótesis de igualdad de varianzas está dado por:
$$F= \frac{S_1^2/\sigma_1^2}{S_1^2/\sigma_1^2}$$
Demuestre que este estadístico tiene distribución F con $(n_1-n_2-1)$ grados de libertad cuando las muestras aleatorias son independientes de tamaños $n_1$ y $n_2$ provenientes de poblaciones normales.

Sea $U_1 \sim \chi^2_(v_1,\lambda)$ y $U_2 \sim \chi^2_(v_2)$, entonces $$W=\frac{\frac{U_1}{v_1}}{\frac{U_2}{v_2}} \sim F_{n_1,n_2,\lambda}$$

$$W=\frac{S_1^2\frac{1}{\sigma_1^2}\frac{n_1-1}{n_1-1}}{S_2^2\frac{1}{\sigma_2^2}\frac{n_1-1}{n_1-1}}$$
$W=\frac{\frac{(n_1-1)S_1^2}{\sigma_1^2}/n_1-1}{\frac{(n_2-1)S_2^2}{\sigma_2^2}/n_2-1}$ por lo que $U_1=\frac{(n_1-1)S_1^2}{\sigma_1^2} \sim \chi^2_(n_1-1)$ y $U_2=\frac{(n_2-1)S_2^2}{\sigma_2^2} \sim \chi^2_(n_2-1)$






